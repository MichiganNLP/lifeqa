<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">

  <title>LifeQA: A Real-Life Dataset for Video Question Answering</title>
  <meta name="description"
        content="LifeQA is a benchmark dataset for Video Question Answering that focuses on day-to-day real-life situations.">
  <meta name="keywords"
        content="LifeQA, VideoQA, Video Question Answering, Computer Vision, Machine Learning, dataset, Natural Language Processing, Videos, YouTube, real life, research, LREC2020, LREC, Machine Learning, Deep Learning, NLP, PyTorch">
  <meta name="author"
        content="Santiago Castro, Mahmoud Azab, Jonathan C. Stroud, Cristina Noujaim, Ruoyao Wang, Jia Deng, and Rada Mihalcea">

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="LifeQA: A Real-Life Dataset for Video Question Answering" />
  <meta property="og:image" content="https://lit.eecs.umich.edu/lifeqa/img/example.png" />
  <meta property="og:image:height" content="630" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:title" content="LifeQA: A Real-Life Dataset for Video Question Answering" />
  <meta property="og:description" content="LifeQA is a benchmark dataset for Video Question Answering that focuses on day-to-day real-life situations." />
  <meta property="og:url" content="https://lit.eecs.umich.edu/lifeqa/" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:site" content="@michigan_AI" />
  <meta name="twitter:creator" content="@michigan_AI" />

  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-34392230-10"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-34392230-10');
  </script>

  <link rel="stylesheet" type="text/css" href="main.css"/>
</head>

<body>

<div class="container">

  <header>
    <a href="https://www.tri.global/"><img id="tri" src="img/tri.png" alt="Toyota Research Institute logo"></a>

    <a href="https://umich.edu/"><img id="um" src="img/um.png" alt="University of Michigan logo"></a>

    <h1>LifeQA: A Real-Life Dataset for Video Question Answering</h1>

    <ul id="quick-links">
      <li><a href="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.536.pdf">Paper</a></li>

      <li><a href="https://github.com/mmazab/LifeQA">Data + Code</a></li>

      <li><a href="https://www.aclweb.org/anthology/2020.lrec-1.536/">ACL Anthology page</a></li>

      <li><a href="https://www.aclweb.org/anthology/2020.lrec-1.536.bib">BibTeX Citation</a></li>
    </ul>
  </header>

  <section class="section-alt">
    <div class="content">
      <h2>Abstract</h2>

      <p id="abstract">
        We introduce <b>LifeQA</b>, a benchmark dataset for video question answering that focuses on day-to-day
        real-life
        situations. Current video question answering datasets consist of movies and TV shows. However, it is well-known
        that these visual domains are not representative of our day-to-day lives. Movies and TV shows, for example,
        benefit from professional camera movements, clean editing, crisp audio recordings, and scripted dialog between
        professional actors. While these domains provide a large amount of data for training models, their properties
        make
        them unsuitable for testing real-life question answering systems. Our dataset, by contrast, consists of video
        clips that represent only real-life scenarios. We collect 275 such video clips and over 2.3k multiple-choice
        questions. In this paper, we analyze the challenging but realistic aspects of LifeQA, and we apply several
        state-of-the-art video question answering models to provide benchmarks for future research.
      </p>
    </div>
  </section>

  <section>
    <div class="content">
      <a href="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.536.pdf">
        <ol id="thumbnails">
          <li><img src="img/thumbs/0.png" alt="thumbnail, page 0"/></li>
          <li><img src="img/thumbs/1.png" alt="thumbnail, page 1"/></li>
          <li><img src="img/thumbs/2.png" alt="thumbnail, page 2"/></li>
          <li><img src="img/thumbs/3.png" alt="thumbnail, page 3"/></li>
          <li><img src="img/thumbs/4.png" alt="thumbnail, page 4"/></li>
          <li><img src="img/thumbs/5.png" alt="thumbnail, page 5"/></li>
          <li><img src="img/thumbs/6.png" alt="thumbnail, page 6"/></li>
        </ol>
      </a>
    </div>
  </section>

  <section>
    <div class="content">
      <ol id="authors">
        <li>
          <a href="https://santi.uy">
            <div class="author-img-container">
              <img src="img/authors/santi.jpeg" alt="Santiago Castro profile picture">
            </div>
            Santiago Castro
          </a>
        </li>
        <li>
          <a href="https://web.eecs.umich.edu/~mazab/">
            <div class="author-img-container">
              <img src="img/authors/mazab.jpeg" alt="Mahmoud Azab profile picture">
            </div>
            Mahmoud Azab
          </a>
        </li>
        <li>
          <a href="https://www.jonathancstroud.com/">
            <div class="author-img-container">
              <img src="img/authors/jonathan.png" alt="Jonathan C. Stroud profile picture">
            </div>
            Jonathan C. Stroud
          </a>
        </li>
        <li>
          <div>
            <div class="author-img-container">
              <img src="img/authors/cristina.jpg" alt="Cristina Noujaim profile picture">
            </div>
            Cristina Noujaim
          </div>
        </li>
        <li>
          <a href="https://wsxzwps.github.io/">
            <div class="author-img-container">
              <img src="img/authors/ruoyao.jpg" alt="Ruoyao Wang profile picture">
            </div>
            Ruoyao Wang
          </a>
        </li>
        <li>
          <a href="https://www.cs.princeton.edu/~jiadeng/">
            <div class="author-img-container">
              <img src="img/authors/jia.jpg" alt="Jia Deng profile picture">
            </div>
            Jia Deng
          </a>
        </li>
        <li>
          <a href="https://web.eecs.umich.edu/~mihalcea/">
            <div class="author-img-container">
              <img src="img/authors/rada.jpg" alt="Rada Mihalcea profile picture">
            </div>
            Rada Mihalcea
          </a>
        </li>
      </ol>

      <p id="affiliation">
        <a href="https://umich.edu/">
          <img id="um-vertical" alt="University of Michigan" src="img/um-vertical.png">
        </a>
      </p>

    </div>
  </section>

  <section class="section-alt">
    <div class="content">
      <h2>Downloads</h2>

      <ul id="downloads">
        <li><a href="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.536.pdf">PDF Paper</a></li>
        <li><a href="https://github.com/mmazab/LifeQA">Data + Code</a> (with instructions)</li>
        <li>
          <a href="https://drive.google.com/drive/folders/1sV1IYoC1oIgjHfSVkIJ-p8GA2hOwx4u1?usp=sharing">
            Pre-extracted features</a>
          (ResNet-152, C3D, and more)
        </li>
        <li>
          <a href="https://github.com/mmazab/LifeQA/tree/master/data/lqa_trans">Manually transcribed captions</a>
        </li>
      </ul>
    </div>
  </section>

  <!--section>
    <div class="content">
      <h2>Examples</h2>

      <p></p>
    </div>
  </section-->

  <footer>
    <div class="content">
      <h2>Acknowledgments</h2>

      <p id="acknowledgments-text">
        We are grateful to Aurelia Bunescu, <a href="https://dsouzadaniel.github.io/">Daniel D'Souza</a>,
        <a href="https://haoopeng.github.io/">Penghao He</a>,
        <a href="https://shubham14.github.io/">Shubham Dash</a>, and
        <a href="http://www-personal.umich.edu/~ywchao/">Yu-Wei Chao</a> for their help with the collection and
        annotation of the dataset. This material is based in part upon work supported by the
        <a href="https://www.tri.global/">Toyota Research Institute ("TRI")</a>. Any opinions, findings, and conclusions
        or recommendations expressed in this material are those of the authors and do not necessarily reflect the views
        of TRI or any other Toyota entity.
      </p>

      <p>
        Web page inspired by the
        <a href="https://cs.stanford.edu/people/ranjaykrishna/densevid/">ActivityNet Captions web page</a>.
      </p>
    </div>
  </footer>

</div>

</body>

</html>
