<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>LifeQA: A Real-life Dataset for Video Question Answering</title>

  <!-- TODO: metadata -->

  <!-- TODO: open graph -->

  <!-- TODO: G Analytics -->

  <link rel="stylesheet" type="text/css" href="main.css"/>
</head>

<body>

<div class="container">

  <header>
    <img id="tri" src="img/tri.png" alt="Toyota Research Institute logo">

    <img id="um" src="img/um.png" alt="University of Michigan logo">

    <h1>LifeQA: A Real-life Dataset for Video Question Answering</h1>

    <ul id="quick-links">
      <li><a href="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.536.pdf">Paper</a></li>

      <li><a href="https://github.com/mmazab/LifeQA">Code</a></li>

      <li><a href="https://www.aclweb.org/anthology/2020.lrec-1.536/">ACL Anthology page</a></li>

      <li><a href="https://www.aclweb.org/anthology/2020.lrec-1.536.bib">BibTeX Citation</a></li>
    </ul>
  </header>

  <section class="section-alt">
    <div class="content">
      <h2>Abstract</h2>

      <p id="abstract">
        We introduce <b>LifeQA</b>, a benchmark dataset for video question answering that focuses on day-to-day
        real-life
        situations. Current video question answering datasets consist of movies and TV shows. However, it is well-known
        that these visual domains are not representative of our day-to-day lives. Movies and TV shows, for example,
        benefit from professional camera movements, clean editing, crisp audio recordings, and scripted dialog between
        professional actors. While these domains provide a large amount of data for training models, their properties
        make
        them unsuitable for testing real-life question answering systems. Our dataset, by contrast, consists of video
        clips that represent only real-life scenarios. We collect 275 such video clips and over 2.3k multiple-choice
        questions. In this paper, we analyze the challenging but realistic aspects of LifeQA, and we apply several
        state-of-the-art video question answering models to provide benchmarks for future research.
      </p>
    </div>
  </section>

  <section>
    <div class="content">
      <a href="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.536.pdf">
        <ol id="thumbnails">
          <li><img src="img/thumbs/0.png" alt="thumbnail, page 0"/></li>
          <li><img src="img/thumbs/1.png" alt="thumbnail, page 1"/></li>
          <li><img src="img/thumbs/2.png" alt="thumbnail, page 2"/></li>
          <li><img src="img/thumbs/3.png" alt="thumbnail, page 3"/></li>
          <li><img src="img/thumbs/4.png" alt="thumbnail, page 4"/></li>
          <li><img src="img/thumbs/5.png" alt="thumbnail, page 5"/></li>
          <li><img src="img/thumbs/6.png" alt="thumbnail, page 6"/></li>
        </ol>
      </a>
    </div>
  </section>

  <section>
    <div class="content">
      <ol id="authors">
        <li>
          <a href="https://santi.uy">
            <div class="author-img-container">
              <img src="img/authors/santi.jpeg" alt="Santiago Castro profile picture">
            </div>
            Santiago Castro
          </a>
        </li>
        <li>
          <a href="https://web.eecs.umich.edu/~mazab/">
            <div class="author-img-container">
              <img src="img/authors/mazab.png" alt="Mahmoud Azab profile picture">
            </div>
            Mahmoud Azab
          </a>
        </li>
        <li>
          <a href="https://www.jonathancstroud.com/">
            <div class="author-img-container">
              <img src="img/authors/jonathan.png" alt="Jonathan C. Stroud profile picture">
            </div>
            Jonathan C. Stroud
          </a>
        </li>
        <li>
          <div>
            <div class="author-img-container">
              <img src="img/authors/cristina.jpg" alt="Cristina Noujaim profile picture">
            </div>
            Cristina Noujaim
          </div>
        </li>
        <li>
          <div>
            <div class="author-img-container">
              <img src="img/authors/ruoyao.jpg" alt="Ruoyao Wang profile picture">
            </div>
            Ruoyao Wang
          </div>
        </li>
        <li>
          <a href="https://www.cs.princeton.edu/~jiadeng/">
            <div class="author-img-container">
              <img src="img/authors/jia.jpg" alt="Jia Deng profile picture">
            </div>
            Jia Deng
          </a>
        </li>
        <li>
          <a href="https://web.eecs.umich.edu/~mihalcea/">
            <div class="author-img-container">
              <img src="img/authors/rada.jpg" alt="Rada Mihalcea profile picture">
            </div>
            Rada Mihalcea
          </a>
        </li>
      </ol>

      <p id="affiliation">
        <a href="https://umich.edu/">
          <img id="um-vertical" alt="University of Michigan" src="img/um-vertical.png">
        </a>
      </p>

    </div>
  </section>

  <section class="section-alt">
    <div class="content">
      <h2>Downloads</h2>

      <p>TODO: file with links, features</p>
    </div>
  </section>

  <section>
    <div class="content">
      <h2>Examples</h2>

      <p>TODO</p>
    </div>
  </section>

  <footer class="section-alt">
    <div class="content">
      <h2>Acknowledgments</h2>

      <p id="acknowledgments-text">
        We are grateful to Aurelia Bunescu, <a href="https://dsouzadaniel.github.io/">Daniel D'Souza</a>,
        <a href="https://haoopeng.github.io/">Penghao He</a>,
        <a href="https://shubham14.github.io/">Shubham Dash</a>, and
        <a href="http://www-personal.umich.edu/~ywchao/">Yu-Wei Chao</a> for their help with the collection and
        annotation of the dataset. This material is based in part upon work supported by the
        <a href="https://www.tri.global/">Toyota Research Institute ("TRI")</a>. Any opinions, findings, and conclusions
        or recommendations expressed in this material are those of the authors and do not necessarily reflect the views
        of TRI or any other Toyota entity.
      </p>

      <p>
        Web page inspired by the
        <a href="https://cs.stanford.edu/people/ranjaykrishna/densevid/">ActivityNet Captions web page</a>.
      </p>
    </div>
  </footer>

</div>

</body>

</html>
